# java并发编程的艺术读书笔记

# 并发编程基础知识

Java代码在编译后会变成Java字节码，字节码被类加载器加载到JVM里，JVM执行字节码，最终需要转化为汇编指令在CPU上执行，Java中所使用的并发机制依赖于JVM的实现和CPU的指令

- ### 上下文切换

  CPU通过时间片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个任务。但是，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再加载这个任务的状态。所以任务从保存到再加载的过程就是一次上下文切换。
  
- ### 如何减少上下文切换

  - 无锁并发编程   多线程竞争锁时，会引起上下文切换，所以多线程处理数据时，可以用一些办法来避免使用锁，如将数据的ID按照Hash算法取模分段，不同的线程处理不同段的数据
  - CAS算法
  - 使用最少线程
  - 协程
  
- ### 减少线程上下文切换实战

  第一步：用jstack命令dump线程信息，看看pid为3117的进程里的线程都在做什么。

  ​	sudo -u admin /opt/ifeve/java/bin/jstack 31177 > /home/tengfei.fangtf/dump17

  第二步：统计所有线程分别处于什么状态，发现300多个线程处于WAITING（onobject-monitor）状态。

  grep java.lang.Thread.State dump17 | awk '{print $2$3$4$5}'
  | sort | uniq -c

  第三步：打开dump文件查看处于WAITING（onobjectmonitor）的线程在做什么。发现这些线程基本全是JBOSS的工作线程，在await。说明JBOSS线程池里线程接收到的任务太少，大量线程都闲着。

  第四步：减少JBOSS的工作线程数，找到JBOSS的线程池配置信息，将maxThreads降到100。

  最后：WAITING的线程少了，系统上下文切换的次数就会少，因为每一次从WAITTING到RUNNABLE都会进行一次上下文的切换

- ### 避免死锁的几个常见方法

  - 避免一个线程同时获取多个锁。
  - 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源
  - 尝试使用定时锁，使用lock.tryLock（timeout）来替代使用内部锁机制。
  - 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况。

- ### 什么是资源限制

  例如，服务器的带宽只有2Mb/s，某个资源的下载速度是1Mb/s每秒，系统启动10个线程下载资源，下载速度不会变成10Mb/s，所以在进行并发编程时，要考虑这些资源的限制。硬件资源限制有带宽的上传/下载速度、硬盘读写速度和CPU的处理速度。软件资源限制有数据库的连接数和socket连接数等。

- ### 资源限制引发的问题

  在并发编程中，将代码执行速度加快的原则是将代码中串行执行的部分变成并发执行，但是如果将某段串行的代码并发执行，因为受限于资源，仍然在串行执行，这时候程序不仅不会加快执行，反而会更慢，因为增加了上下文切换和资源调度的时间。

- ### 如何解决资源限制的问题

  对于硬件资源限制，可以考虑使用集群并行执行程序。对于软件资源限制，可以考虑使用资源池将资源复用。比如使用连接池将数据库和Socket连接复用，或者在调用对方webservice接口获取数据时，只建立一个连接。

- ### 如何在资源限制的情况下，让程序执行得更快呢

  根据不同的资源限制调整程序的并发度，比如下载文件程序依赖于两个资源——带宽和硬盘读写速度。有数据库操作时，涉及数据库连接数，如果SQL语句执行非常快，而线程的数量比数据库连接数大很多，则某些线程会被阻塞，等待数据库连接。

# volatile

- ## 可见性

  可见性的意思是当一个线程修改一个共享变量时，另外一个线程能读到这个修改的值。volatile它在多处理器开发中保证了共享变量的“可见性”。如果volatile变量修饰符使用恰当的话，它比synchronized的使用和执行成本更低，因为它不会引起线程上下文的切换和调度。

- ## volatile的定义

  Java语言规范第3版中对volatile的定义如下：Java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致地更新，线程应该确保通过排他锁单独获得这个变量。Java语言提供了volatile，在某些情况下比锁要更加方便。如果一个字段被声明成volatile，Java线程内存模型确保所有线程看到这个变量的值是一致的。

- ## volatile实现原理

  有volatile变量修饰的共享变量进行写操作的时候生成的汇编代码 “lock addl $0×0,” Lock前缀的指令在多核处理器下会引发了两件事情。

  1）将当前处理器缓存行的数据写回到系统内存。

  2）这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效。

  volatile的两条实现原则

  Lock前缀指令会引起处理器缓存回写到内存

  一个处理器的缓存回写到内存会导致其他处理器的缓存无效。

  > 为了提高处理速度，处理器不直接和内存进行通信，而是先将系统内存的数据读到内部缓存（L1，L2或其他）后再进行操作，但操作完不知道何时会写到内存。如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写回到系统内存。但是，就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题。所以，在多处理器下，为了保证各个处理器的缓存是一致的，就会实现**缓存一致性协议**，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓

# synchronized的实现原理与应用

当一个线程试图访问同步代码块时，它首先必须得到锁，退出或抛出异常时必须释放锁。

Java中的每一个对象都可以作为锁。具体表现为以下3种形式。

·对于普通同步方法，锁是当前实例对象。

·对于静态同步方法，锁是当前类的Class对象。

·对于同步方法块，锁是Synchonized括号里配置的对象。

> 从JVM规范中可以看到Synchonized在JVM里的实现原理，JVM基于进入和退出Monitor对象来实现方法同步和代码块同步，但两者的实现细节不一样。代码块同步是使用monitorenter和monitorexit指令实现的，而方法同步是使用另外一种方式实现的，细节在JVM规范里并没有详细说明。但是，方法的同步同样可以使用这两个指令来实现。
>
>    
>
> monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处，JVM要保证每个monitorenter必须有对应的monitorexit与之配对。任何对象都有一个monitor与之关联，当且一个monitor被持有后，它将处于锁定状态。线程执行到monitorenter指令时，将会尝试获取对象所对应的monitor的所有权，即尝试获得对象的锁。

### Java对象头

由于Java面向对象的思想，在JVM中需要大量存储对象，存储时为了实现一些额外的功能，需要在对象中添加一些标记字段用于增强对象功能，这些标记字段组成了对象头。

JVM中对象头的方式有以下两种

在32位虚拟机中，1字宽等于4字节，即32bit

#### 1.1.普通对象

| 长度     | 内容                   | 说明                                   |
| -------- | ---------------------- | -------------------------------------- |
| 32/64bit | Mark Word              | 存储对象的hashCode、分代年龄、锁标记为 |
| 32/64bit | Class metadata Address | 存储到对象类型数据的指针               |

#### 1.2.数组对象

| 长度     | 内容                   | 说明                                   |
| -------- | ---------------------- | -------------------------------------- |
| 32/64bit | Mark Word              | 存储对象的hashCode、分代年龄、锁标记为 |
| 32/64bit | Class metadata Address | 存储到对象类型数据的指针               |
| 32/32bit | Array Length           | 数组长度                               |

32位JVM的Mark Word的默认存储结构

| 锁状态   | 25bit          | 4bit           | 1bit是否偏向锁 | 2bit锁标志位 |
| -------- | -------------- | -------------- | -------------- | ------------ |
| 无锁状态 | 对象的hashCode | 对象的分代年龄 | 0              | 01           |

在运行期间，Mark Word里存储的数据会随着锁标志位的变化而变化。

![](..\..\img\java heard.jpg)

在64位虚拟机下，Mark Word是64bit大小的

| 锁状态 | 25bit           | 31bit        | 1bit<br />cms_free | 4bit<br />分代年龄 | 1bit<br />偏向锁 | 2bit<br />锁标志位 |
| ------ | --------------- | ------------ | ------------------ | ------------------ | ---------------- | ------------------ |
| 无锁   | unused          | hashCode     |                    |                    | 0                | 01                 |
| 偏向锁 | ThreadID(54bit) | +Epoch(2bit) |                    |                    | 1                | 01                 |

### 锁的升级与对比

Java SE 1.6为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”，在Java SE 1.6中，锁一共有4种状态，级别从低到高依次是：无锁状态、偏向锁状态、轻量级锁状态和重量级锁状态，这几个状态会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。

#### 1.偏向锁

> HotSpot的作者经过研究发现，大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁，只需简单地测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁。如果测试成功，表示线程已经获得了锁。如果测试失败，则需要再测试一下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁）：如果没有设置，则使用CAS竞争锁；如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。
>
> 偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有正在执行的字节码）。它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态；如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程

**关闭偏向锁**

偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活，如有必要可以使用JVM参数来关闭延迟：-XX:BiasedLockingStartupDelay=0。如果你确定应用程序里所有的锁通常情况下处于竞争状态，可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，那么程序默认会进入轻量级锁状态。

![](..\..\img\jvm_lock1.jpg)

#### 2.轻量级锁

##### （1）轻量级锁加锁

线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。

##### （2）轻量级锁解锁

轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。

![](..\..\img\jvm_lock2.png)

因为自旋会消耗CPU，为了避免无用的自旋（比如获得锁的线程被阻塞住了），一旦锁升级成重量级锁，就不会再恢复到轻量级锁状态。当锁处于这个状态下，其他线程试图获取锁时，都会被阻塞住，当持有锁的线程释放锁之后会唤醒这些线程，被唤醒的线程就会进行新一轮的夺锁之争。

锁的优缺点对比。

| 锁       | 优点                                     | 缺点                                          | 使用场景                           |
| -------- | ---------------------------------------- | --------------------------------------------- | ---------------------------------- |
| 偏向锁   | 加锁和解锁不需要额外的开销               | 如果线程间存在竞争，会带来额外的锁撤销的消耗  | 只有一个线程访问同步块             |
| 轻量级锁 | 竞争的线程不会阻塞，提高了程序的响应速度 | 如果始终得不到锁竞争的线程，使用自旋会消耗cpu | 追求响应时间，同步代码执行非常快   |
| 重量级锁 | 线程竞争不是用自旋，不会消耗cpu          | 线程阻塞，响应时间缓慢                        | 追求吞吐量，同步代码块执行时间较长 |

### 原子操作的实现原理

#### 1、定义

原子（atomic）本意是“不能被进一步分割的最小粒子”，而原子操作（atomic operation）意为“不可被中断的一个或一系列操作”。

> **CPU术语定义：**
> 1、缓存行（Cache line） 缓存的最小操作单元
> 2、比较并交换 （compare and swap）  cas操作需要输入两个值，一个旧值：期望操作前的值，和一个新值，		在操作期间先比较旧值有没有发生变化，如果没发生变化才交换成新值，发生变化则不交换。
> 3、CPU流水线  （CPU pipeline） cpu流水线的工作方式就像工业生产上的装配流水线，在CPU中由5~6个不同		功能的电路单元组成一条指令处理流水线，然后将一条X86指令分成5~6步后再由这些电路单元分别执行，
>         这样就能实现在一个cpu时钟周期完成一条指令，因此提供CPU的运算速度。
> 4、内存顺序冲突 （memery order violation） 内存顺序冲突一般是由假共享引起的，假共享是指多个CPU同时		修改同一个缓存行的不同部分而引起其中一个修改无效，当出现这个内存顺序冲突时，CPU必须清空流水线。

#### 2、处理器如何实现原子操作：

首先处理器会自动保证基本的内存操作的原子性。处理器保证从系统内存中读取或者写入一个字节是原子的，意思是当一个处理器读取一个字节时，其他处理器不能访问这个字节的内存地址。

1、使用总线锁保证原子性：

> 第一个机制是通过总线锁保证原子性。如果多个处理器同时对共享变量进行读改写操作（i++就是经典的读改写操作），那么共享变量就会被多个处理器同时进行操作，这样读改写操作就不是原子的，操作完之后共享变量的值会和期望的不一致。举个例子，如果i=1，我们进行两次i++操作，我们期望的结果是3，但是有可能结果是2，原因可能是多个处理器同时从各自的缓存中读取变量i，分别进行加1操作，然后分别写入系统内存中。那么，想要保证读改写共享变量的操作是原子的，就必须保证CPU1读改写共享变量的时候，CPU2不能操作缓存了该共享变量内存地址的缓存。处理器使用总线锁就是来解决这个问题的。所谓总线锁就是使用处理器提供的一个LOCK＃信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住，那么该处理器可以独占共享内存。

2、使用缓存缓存锁保证原子性

> 第二个机制是通过缓存锁定来保证原子性。在同一时刻，我们只需保证对某个内存地址的操作是原子性即可，<u>但总线锁定把CPU和内存之间的通信锁住了，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以总线锁定的开销比较大</u>，目前处理器在某些场合下使用缓存锁定代替总线锁定来进行优化。
>
> 频繁使用的内存会缓存在处理器的L1、L2和L3高速缓存里，那么原子操作就可以直接在处理器内部缓存中进行，并不需要声明总线锁，在Pentium 6和目前的处理器中可以使用“缓存锁定”的方式来实现复杂的原子性。所谓“缓存锁定”是指内存区域如果被缓存在处理器的缓存行中，并且在Lock操作期间被锁定，那么当它执行锁操作回写到内存时，处理器不在总线上声言LOCK＃信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性，因为缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时，会使缓存行无效，
>
> 但是有两种情况下处理器不会使用缓存锁定。
>
> 第一种情况是：当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行（cache line）时，则处理器会调用总线锁定。
>
> 第二种情况是：有些处理器不支持缓存锁定。对于Intel 486和Pentium处理器，就算锁定的内存区域在处理器的缓存行中也会调用总线锁定。
>
> 针对以上两个机制，我们通过Intel处理器提供了很多Lock前缀的指令来实现。例如，位测试和修改指令：BTS、BTR、BTC；交换指令XADD、CMPXCHG，以及其他一些操作数和逻辑指令（如ADD、OR）等，被这些指令操作的内存区域就会加锁，导致其他处理器不能同时访问它。